# 評価指標の読み方ガイド

本ガイドは `multiclass_train/trainer.py` が出力する `metrics.json` / `metrics_summary.csv` などに記録される各指標の意味と、どのように解釈すればよいかをまとめたものです。レポートを確認する際のチートシートとしてご利用ください。

## 共通
- **前提**: すべての指標はハッシュVIN（車両）ごとに独立して算出されます。比較する際は同一VINの結果同士で評価してください。
- **HEADクラスタ**: 充電直後の放置候補として採用された上位クラスタ群（最大 `head_k` 件）。`OTHER` はHEADに含まれなかったクラスタをまとめたグループです。

---

## `train_score`
- **定義**: AutoGluon の `predictor.evaluate(train_data)` による学習データ（train split）上でのスコア。
- **用途**: モデルがきちんと学習できたか（損失が計算できているか）の簡易チェックに留める。
- **注意**: 学習データで評価しているため、基本的には高いスコアになります。過学習判定には利用せず、`strict_top1_accuracy` 等の検証用指標を必ず参照してください。

---

## `strict_top1_accuracy`
- **定義**: テストデータ全体での Top-1 正解率。`OTHER` を含むすべてのクラスを対象とし、予測ラベルと真値が一致した割合。
- **解釈**: 実運用に最も近い「総合精度」。`OTHER` が多いと値が高く見積もられる場合があるので、`class_stats` や `head_only_top1_accuracy` とセットで確認する。
- **目安**: `0.3〜0.4` 以上で実利用を検討できる水準（データ量や業務要件によって調整）。

---

## `head_only_top1_accuracy`
- **定義**: 真値が HEAD クラスタに属するサンプルのみを対象にした Top-1 正解率。`OTHER` を除外。
- **解釈**: 充電直後に現実的に選ばれる放置先に絞った精度。こちらが低い場合、HEADクラスタの選定や特徴量の改善が必要。
- **目安**: HEADクラスタが 3〜5 件程度なら `0.5` 以上を目指す。`strict_top1_accuracy` との差が大きい場合は `OTHER` 予測に引っ張られている可能性がある。

---

## `class_recalls`
- **定義**: HEAD クラスタそれぞれの再現率（Recall）。`CID`: `テストデータで真値がCIDのときにCIDと予測できた割合`。
- **解釈**: クラスタ単位の抜け漏れ具合を確認する。値が `None` のクラスタはテストに真値が存在しなかったことを意味する。
- **目安**: 需要の高いクラスタ（HOME 等）は `0.5` 前後を狙う。低い場合は特徴量の見直しや HEAD の設定変更を検討。

---

## `confusion_matrix`
- **定義**: HEAD クラスタ間の混同行列。`matrix[i][j]` は真値が `head_clusters[i]`、予測が `head_clusters[j]` だった件数。
- **解釈**: どのクラスタ同士を取り違えているかを把握できる。行和が真値件数、列和が予測件数。
- **使い方**: 行ベースで割合に正規化すると視覚的に把握しやすい。特定のクラスタへ誤って流れがちなら、距離や時間特徴のチューニング余地あり。

---

## `threshold_metrics`
- **定義**: 予測確率の最大値が指定した閾値（例: 0.5, 0.7, 0.9）を超えたケースのみを対象としたカバレッジ（割合）と正解率。
    - `coverage`: 閾値以上の確信を持てたサンプルの割合。
    - `accuracy`: その subset での Top-1 正解率。
- **解釈**: スコアの信頼度に応じて予測を採択／保留する際の指標。高い閾値で coverage が低すぎる場合は確率キャリブレーションを検討。
- **目安**: 0.7 以上の閾値でも coverage が 30〜40% あり、accuracy が 0.6 を超えると「確信が高い予測のみ採用」といった運用が可能になる。

---

## `class_stats`
- **定義**: クラスタ別の件数と精度まとめ。各キーの意味は以下の通り。
    - `is_head`: HEAD クラスタかどうか。
    - `overall_count`: 全データ（train+valid+test）における真値件数。
    - `overall_share`: 全データに占める割合（0〜1）。
    - `train_count` / `valid_count` / `test_count`: 各 split での真値件数。
    - `test_correct` / `test_incorrect`: テストで正しく当てた件数・外した件数。
    - `test_accuracy`: テストでの正答率（件数が 0 のときは `null`）。
- **解釈**: クラスタの母数と精度を一括で確認できる。`overall_share` が小さいクラスタで `test_accuracy` が低い場合は、学習データが不足している可能性が高い。
- **使い方**: 母数の多い HOME / WORK などが低精度なら重要課題。母数が極端に小さいクラスタは HEAD の対象から外すことも検討。

---

## `feature_importance_top` / `feature_importance_path`
- **定義**: AutoGluon の `predictor.feature_importance` に基づく上位特徴量（importance）。`feature_importance_path` は全結果CSVへのパス。
- **解釈**: モデルが重視した特徴量を確認できる。特徴名に `time_` 系が多い場合は時間帯依存を、`dist_to_` が多い場合は距離が支配的であることを示す。
- **活用**: 特徴量追加／削除の優先度を決める指標。重要度が低い特徴はON/OFFで精度の影響を検証する。

---

## `model_leaderboard_top` / `model_leaderboard_path`
- **定義**: AutoGluon の `predictor.leaderboard` 出力。サブモデル名、スコア、推定時間などが記録される。
- **解釈**: どのアルゴリズムが最終アンサンブルに貢献したかを把握できる。上位モデルの `score_val` を比較し最適モデルを分析。
- **活用**: モデル種類ごとの得意不得意を把握し、プリセットの変更やリソース制約の調整に役立てる。

---

## `explanation_error` / `explanation_features` / `impact_*`
- **定義**: `impact_<feature>` 列は、該当特徴を中央値に置き換えたときの Top-1 確率低下量。`explanation_features` は impact を計算した特徴リスト。
- **解釈**: 予測理由を数値的に把握する指標。値が大きいほど「その特徴が予測を押し上げている」ことを意味する。
- **活用**: 誤判定ケースの分析や説明資料の作成に利用。`explanation_error` が出ている場合は impact 算出に失敗したため、ログを確認する。

---

## 参考: 推奨の読み方フロー
1. `strict_top1_accuracy` と `head_only_top1_accuracy` を比較し、全体精度とHEAD精度のギャップを把握する。
2. `class_stats` と `class_recalls` で重要クラスタの母数・精度を確認。問題箇所があれば `confusion_matrix` で誤推定先を調べる。
3. `threshold_metrics` を見て、確信度に応じた利用方法（例: 高確率だけ通知）を検討する。
4. `feature_importance` / `impact_*` で改善アイデア（有効な特徴量、無効な特徴量）を洗い出す。

この手順で確認すると、どこに課題があるのかを短時間で把握できます。さらに詳しく分析したい場合は `metrics.json` を開き、各ヘッダに沿って詳細数値を確認してください。
