{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EV 充電 → 長時間放置 予測 (Ranking)\n",
    "\n",
    "このノートブックは、`AutoGluon` を用いて『充電直後に最初に発生する長時間放置 (>=6h) の場所クラスタ』をランキング予測するための学習・評価・推論の一連の手順を示します。\n",
    "\n",
    "- 特徴量生成: 充電イベントごとの文脈 (曜日/時刻/充電クラスタ) と候補放置クラスタの過去傾向 (人気度/代表時刻/距離など) を組み合わせたペア特徴\n",
    "- 学習: 候補集合に対する二値分類 (正例=実際の放置クラスタ)。陽性確率をランキングスコアとして使用\n",
    "- 評価: Top-k, MRR, MAP, NDCG@k を charge-group ごとに算出\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ライブラリ読み込み\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from autogluon.tabular import TabularPredictor\n",
    "# 自作ユーティリティ (本リポジトリ内)\n",
    "import sys\n",
    "sys.path.append(str(Path(\"EV-Battery-Parking-Degradation-Mitigation\").resolve()))\n",
    "from ranking.dataset import (\n",
    "    load_sessions,\n",
    "    prepare_sessions,\n",
    "    build_charge_to_next_long_table,\n",
    "    compute_cluster_centroids_by_vehicle,\n",
    "    build_candidate_pool_per_vehicle,\n",
    "    build_ranking_training_data,\n",
    "    get_feature_columns,\n",
    ")\n",
    "from ranking.metrics import (\n",
    "    top_k_accuracy_at_k,\n",
    "    mean_reciprocal_rank,\n",
    "    mean_average_precision,\n",
    "    ndcg_at_k,\n",
    ")\n",
    "DATA_PATH = Path(\"../eda/ev_sessions_test.csv\")\n",
    "OUTDIR = Path(\"./outputs/ranking_demo\")\n",
    "OUTDIR.mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# パラメータ（必要に応じて調整してください）\n",
    "LONG_PARK_THRESHOLD_MIN = 360  # 長時間放置の定義（分）\n",
    "CAND_TOP_N_PER_VEHICLE = 10   # 車両別候補 Top-N\n",
    "CAND_GLOBAL_TOP_N = 20        # 全体候補 Top-N（補完用）\n",
    "NEG_SAMPLE_K = 10             # 学習用の負例サンプリング K（0/負なら無効）\n",
    "HOUR_BIN_SIZE = 3             # 時刻ビン幅（h）。例: 3→ 0-2,3-5,... の 3h ビン\n",
    "ALPHA_SMOOTH = 1.0            # ラプラス平滑化の α\n",
    "AG_PRESETS = 'medium_quality_faster_train'  # AutoGluon のプリセット\n",
    "TIME_LIMIT = 300              # 学習の時間制限（秒）\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. データ読込と前処理\n",
    "\n",
    "- タイムゾーンは Asia/Tokyo に正規化\n",
    "- 長時間放置 (>=6h) の識別と、充電 → 次の長時間放置 (次の充電が来るまで) のリンク付け\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hashvin</th>\n",
       "      <th>weekday</th>\n",
       "      <th>charge_cluster</th>\n",
       "      <th>charge_start_time</th>\n",
       "      <th>charge_start_hour</th>\n",
       "      <th>charge_end_time</th>\n",
       "      <th>park_cluster</th>\n",
       "      <th>park_start_time</th>\n",
       "      <th>park_start_hour</th>\n",
       "      <th>park_duration_minutes</th>\n",
       "      <th>gap_minutes</th>\n",
       "      <th>dist_charge_to_park_km</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hv_0001_demo</td>\n",
       "      <td>1</td>\n",
       "      <td>505</td>\n",
       "      <td>2025-09-02 18:30:00</td>\n",
       "      <td>18</td>\n",
       "      <td>2025-09-02 19:12:00</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2025-09-02 20:30:00</td>\n",
       "      <td>20.0</td>\n",
       "      <td>660.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>3.793725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hv_0001_demo</td>\n",
       "      <td>2</td>\n",
       "      <td>505</td>\n",
       "      <td>2025-09-03 18:45:00</td>\n",
       "      <td>18</td>\n",
       "      <td>2025-09-03 19:29:00</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2025-09-03 20:30:00</td>\n",
       "      <td>20.0</td>\n",
       "      <td>660.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>3.793725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hv_0001_demo</td>\n",
       "      <td>3</td>\n",
       "      <td>606</td>\n",
       "      <td>2025-09-04 18:30:00</td>\n",
       "      <td>18</td>\n",
       "      <td>2025-09-04 19:18:00</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2025-09-04 20:30:00</td>\n",
       "      <td>20.0</td>\n",
       "      <td>660.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>4.558132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hv_0001_demo</td>\n",
       "      <td>4</td>\n",
       "      <td>505</td>\n",
       "      <td>2025-09-05 18:30:00</td>\n",
       "      <td>18</td>\n",
       "      <td>2025-09-05 19:31:00</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2025-09-05 20:30:00</td>\n",
       "      <td>20.0</td>\n",
       "      <td>660.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>3.793725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hv_0001_demo</td>\n",
       "      <td>5</td>\n",
       "      <td>606</td>\n",
       "      <td>2025-09-06 14:30:00</td>\n",
       "      <td>14</td>\n",
       "      <td>2025-09-06 15:12:00</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2025-09-06 20:30:00</td>\n",
       "      <td>20.0</td>\n",
       "      <td>660.0</td>\n",
       "      <td>318.0</td>\n",
       "      <td>4.558132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>hv_0001_demo</td>\n",
       "      <td>6</td>\n",
       "      <td>505</td>\n",
       "      <td>2025-09-07 12:45:00</td>\n",
       "      <td>12</td>\n",
       "      <td>2025-09-07 13:30:00</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2025-09-07 20:30:00</td>\n",
       "      <td>20.0</td>\n",
       "      <td>660.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>3.793725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>hv_0001_demo</td>\n",
       "      <td>1</td>\n",
       "      <td>505</td>\n",
       "      <td>2025-09-09 20:15:00</td>\n",
       "      <td>20</td>\n",
       "      <td>2025-09-09 20:49:00</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2025-09-09 20:30:00</td>\n",
       "      <td>20.0</td>\n",
       "      <td>660.0</td>\n",
       "      <td>-19.0</td>\n",
       "      <td>3.793725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>hv_0001_demo</td>\n",
       "      <td>2</td>\n",
       "      <td>505</td>\n",
       "      <td>2025-09-10 19:00:00</td>\n",
       "      <td>19</td>\n",
       "      <td>2025-09-10 19:35:00</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2025-09-10 20:30:00</td>\n",
       "      <td>20.0</td>\n",
       "      <td>660.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>3.793725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>hv_0001_demo</td>\n",
       "      <td>3</td>\n",
       "      <td>505</td>\n",
       "      <td>2025-09-11 18:45:00</td>\n",
       "      <td>18</td>\n",
       "      <td>2025-09-11 19:24:00</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2025-09-11 20:30:00</td>\n",
       "      <td>20.0</td>\n",
       "      <td>660.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>3.793725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>hv_0001_demo</td>\n",
       "      <td>4</td>\n",
       "      <td>505</td>\n",
       "      <td>2025-09-12 20:45:00</td>\n",
       "      <td>20</td>\n",
       "      <td>2025-09-12 21:33:00</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2025-09-13 20:30:00</td>\n",
       "      <td>20.0</td>\n",
       "      <td>660.0</td>\n",
       "      <td>1377.0</td>\n",
       "      <td>3.793725</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        hashvin  weekday  charge_cluster   charge_start_time  \\\n",
       "0  hv_0001_demo        1             505 2025-09-02 18:30:00   \n",
       "1  hv_0001_demo        2             505 2025-09-03 18:45:00   \n",
       "2  hv_0001_demo        3             606 2025-09-04 18:30:00   \n",
       "3  hv_0001_demo        4             505 2025-09-05 18:30:00   \n",
       "4  hv_0001_demo        5             606 2025-09-06 14:30:00   \n",
       "5  hv_0001_demo        6             505 2025-09-07 12:45:00   \n",
       "6  hv_0001_demo        1             505 2025-09-09 20:15:00   \n",
       "7  hv_0001_demo        2             505 2025-09-10 19:00:00   \n",
       "8  hv_0001_demo        3             505 2025-09-11 18:45:00   \n",
       "9  hv_0001_demo        4             505 2025-09-12 20:45:00   \n",
       "\n",
       "   charge_start_hour     charge_end_time  park_cluster     park_start_time  \\\n",
       "0                 18 2025-09-02 19:12:00         101.0 2025-09-02 20:30:00   \n",
       "1                 18 2025-09-03 19:29:00         101.0 2025-09-03 20:30:00   \n",
       "2                 18 2025-09-04 19:18:00         101.0 2025-09-04 20:30:00   \n",
       "3                 18 2025-09-05 19:31:00         101.0 2025-09-05 20:30:00   \n",
       "4                 14 2025-09-06 15:12:00         101.0 2025-09-06 20:30:00   \n",
       "5                 12 2025-09-07 13:30:00         101.0 2025-09-07 20:30:00   \n",
       "6                 20 2025-09-09 20:49:00         101.0 2025-09-09 20:30:00   \n",
       "7                 19 2025-09-10 19:35:00         101.0 2025-09-10 20:30:00   \n",
       "8                 18 2025-09-11 19:24:00         101.0 2025-09-11 20:30:00   \n",
       "9                 20 2025-09-12 21:33:00         101.0 2025-09-13 20:30:00   \n",
       "\n",
       "   park_start_hour  park_duration_minutes  gap_minutes  dist_charge_to_park_km  \n",
       "0             20.0                  660.0         78.0                3.793725  \n",
       "1             20.0                  660.0         61.0                3.793725  \n",
       "2             20.0                  660.0         72.0                4.558132  \n",
       "3             20.0                  660.0         59.0                3.793725  \n",
       "4             20.0                  660.0        318.0                4.558132  \n",
       "5             20.0                  660.0        420.0                3.793725  \n",
       "6             20.0                  660.0        -19.0                3.793725  \n",
       "7             20.0                  660.0         55.0                3.793725  \n",
       "8             20.0                  660.0         66.0                3.793725  \n",
       "9             20.0                  660.0       1377.0                3.793725  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "charges: 21 with_label: 19\n"
     ]
    }
   ],
   "source": [
    "sessions = load_sessions(DATA_PATH)\n",
    "sessions = prepare_sessions(sessions, long_park_threshold_minutes=LONG_PARK_THRESHOLD_MIN)\n",
    "c2p = build_charge_to_next_long_table(sessions)\n",
    "display(c2p.head(10))\n",
    "print(\"charges:\", len(c2p), \"with_label:\", c2p[\"park_cluster\"].notna().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 候補集合と特徴量の構築\n",
    "\n",
    "- 車両別の長時間放置クラスタ頻度 TopN を候補に、足りない場合は全体 TopN で補完\n",
    "- 候補クラスタの代表座標 (centroid) と、充電終了地点からの距離\n",
    "- 候補クラスタの人気度 (global/vehicle)、代表開始時刻、充電時刻との循環距離\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ranking rows: 38 groups: 19\n"
     ]
    }
   ],
   "source": [
    "centroids = compute_cluster_centroids_by_vehicle(sessions)\n",
    "cand_pool = build_candidate_pool_per_vehicle(\n",
    "    sessions, top_n_per_vehicle=10, global_top_n=20\n",
    ")\n",
    "df_rank = build_ranking_training_data(\n",
    "    df_sessions=sessions,\n",
    "    charge_to_long=c2p,\n",
    "    candidate_pool=cand_pool,\n",
    "    centroids_by_vehicle=centroids,\n",
    "    negative_sample_k=10,\n",
    ")\n",
    "df_rank.head()\n",
    "print(\"ranking rows:\", len(df_rank), \"groups:\", df_rank[\"group_id\"].nunique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 学習と検証分割 (group 単位)\n",
    "\n",
    "- group_id (充電イベント) 単位で 80/20 分割\n",
    "- AutoGluon の二値分類を使用 (陽性=正解クラスタ)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preset alias specified: 'medium_quality_faster_train' maps to 'medium_quality'.\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.12.10\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.26200\n",
      "CPU Count:          16\n",
      "Memory Avail:       18.09 GB / 31.17 GB (58.0%)\n",
      "Disk Space Avail:   834.74 GB / 930.73 GB (89.7%)\n",
      "===================================================\n",
      "Presets specified: ['medium_quality_faster_train']\n",
      "Using hyperparameters preset: hyperparameters='default'\n",
      "Beginning AutoGluon training ... Time limit = 300s\n",
      "AutoGluon will save models to \"c:\\workspace\\src\\kaggle\\ml-study\\EV-Battery-Parking-Degradation-Mitigation\\train\\outputs\\ranking_demo\\autogluon\"\n",
      "Train Data Rows:    32\n",
      "Train Data Columns: 14\n",
      "Label Column:       label\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    18518.26 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.01 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 6 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 2): ['hashvin', 'same_as_charge_cluster']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tUnused Original Features (Count: 3): ['cand_pop_global', 'cand_mean_start_hour', 'cand_hist_count']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 3 | ['cand_pop_global', 'cand_mean_start_hour', 'cand_hist_count']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 6 | ['charge_start_hour', 'charge_hour_sin', 'charge_hour_cos', 'cand_pop_vehicle', 'cand_hour_diff', ...]\n",
      "\t\t('int', [])   : 3 | ['charge_cluster', 'candidate_cluster', 'weekday']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 5 | ['charge_start_hour', 'charge_hour_sin', 'charge_hour_cos', 'cand_hour_diff', 'dist_charge_to_cand_km']\n",
      "\t\t('int', [])       : 1 | ['weekday']\n",
      "\t\t('int', ['bool']) : 3 | ['charge_cluster', 'candidate_cluster', 'cand_pop_vehicle']\n",
      "\t0.0s = Fit runtime\n",
      "\t9 features in original data used to generate 9 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.00 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.04s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n",
      "\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 25, Val Rows: 7\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}],\n",
      "\t'XGB': [{}],\n",
      "\t'FASTAI': [{}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "Fitting 11 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT ... Training model for up to 299.96s of the 299.96s of remaining time.\n",
      "\tFitting with cpus=8, gpus=0, mem=0.0/17.9 GB\n",
      "\tWarning: Exception caused LightGBMXT to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. A quick tip is to install via `pip install autogluon.tabular[lightgbm]==1.4.0`.\n",
      "Fitting model: LightGBM ... Training model for up to 296.40s of the 296.40s of remaining time.\n",
      "\tFitting with cpus=8, gpus=0, mem=0.0/17.9 GB\n",
      "\tWarning: Exception caused LightGBM to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. A quick tip is to install via `pip install autogluon.tabular[lightgbm]==1.4.0`.\n",
      "Fitting model: RandomForestGini ... Training model for up to 296.30s of the 296.30s of remaining time.\n",
      "\tFitting with cpus=16, gpus=0\n",
      "\t1.0\t = Validation score   (roc_auc)\n",
      "\t0.45s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ... Training model for up to 295.82s of the 295.82s of remaining time.\n",
      "\tFitting with cpus=16, gpus=0\n",
      "\t1.0\t = Validation score   (roc_auc)\n",
      "\t0.28s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: CatBoost ... Training model for up to 295.52s of the 295.52s of remaining time.\n",
      "\tFitting with cpus=8, gpus=0\n",
      "\tWarning: Exception caused CatBoost to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.4.0`.\n",
      "Fitting model: ExtraTreesGini ... Training model for up to 295.41s of the 295.41s of remaining time.\n",
      "\tFitting with cpus=16, gpus=0\n",
      "\t1.0\t = Validation score   (roc_auc)\n",
      "\t0.29s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ... Training model for up to 295.08s of the 295.08s of remaining time.\n",
      "\tFitting with cpus=16, gpus=0\n",
      "\t1.0\t = Validation score   (roc_auc)\n",
      "\t0.29s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ... Training model for up to 294.76s of the 294.76s of remaining time.\n",
      "\tFitting with cpus=8, gpus=0, mem=0.0/17.9 GB\n",
      "\tWarning: Exception caused NeuralNetFastAI to fail during training (ImportError)... Skipping this model.\n",
      "\t\tImport fastai failed. A quick tip is to install via `pip install autogluon.tabular[fastai]==1.4.0`. \n",
      "Fitting model: XGBoost ... Training model for up to 294.65s of the 294.65s of remaining time.\n",
      "\tFitting with cpus=8, gpus=0\n",
      "\tWarning: Exception caused XGBoost to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import xgboost` failed. A quick tip is to install via `pip install autogluon.tabular[xgboost]==1.4.0`.\n",
      "Fitting model: NeuralNetTorch ... Training model for up to 294.53s of the 294.53s of remaining time.\n",
      "\tFitting with cpus=8, gpus=0, mem=0.0/17.9 GB\n",
      "c:\\workspace\\src\\kaggle\\ml-study\\venv\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\t0.8333\t = Validation score   (roc_auc)\n",
      "\t0.99s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ... Training model for up to 293.54s of the 293.54s of remaining time.\n",
      "\tFitting with cpus=8, gpus=0, mem=0.0/17.8 GB\n",
      "\tWarning: Exception caused LightGBMLarge to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. A quick tip is to install via `pip install autogluon.tabular[lightgbm]==1.4.0`.\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 299.96s of the 293.38s of remaining time.\n",
      "\tEnsemble Weights: {'RandomForestGini': 1.0}\n",
      "\t1.0\t = Validation score   (roc_auc)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 6.65s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 462.7 rows/s (7 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"c:\\workspace\\src\\kaggle\\ml-study\\EV-Battery-Parking-Degradation-Mitigation\\train\\outputs\\ranking_demo\\autogluon\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<autogluon.tabular.predictor.predictor.TabularPredictor at 0x298e5b1df40>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# group-wise split\n",
    "gids = df_rank[\"group_id\"].unique()\n",
    "rng = np.random.default_rng(42)\n",
    "rng.shuffle(gids)\n",
    "n_val = max(1, int(0.2 * len(gids)))\n",
    "val_ids = set(gids[:n_val])\n",
    "train_df = df_rank[~df_rank[\"group_id\"].isin(val_ids)].copy()\n",
    "val_df = df_rank[df_rank[\"group_id\"].isin(val_ids)].copy()\n",
    "features, cat_cols = get_feature_columns(df_rank)\n",
    "label = \"label\"\n",
    "predictor = TabularPredictor(\n",
    "    label=label,\n",
    "    path=str(OUTDIR / \"autogluon\"),\n",
    "    problem_type=\"binary\",\n",
    "    eval_metric=\"roc_auc\",\n",
    ")\n",
    "predictor.fit(\n",
    "    train_data=train_df[[*features, label]],\n",
    "    time_limit=TIME_LIMIT,\n",
    "    presets=\"medium_quality_faster_train\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 予測スコアとランキング評価\n",
    "\n",
    "- 確率スコアで降順ソートし、Top-k 命中、MRR、MAP、NDCG@3 を算出\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "top1      0.666667\n",
       "top3      1.000000\n",
       "MRR       0.833333\n",
       "MAP       0.833333\n",
       "NDCG@3    0.876977\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "proba = predictor.predict_proba(val_df[features])\n",
    "if isinstance(proba, pd.DataFrame):\n",
    "    scores = proba[1].to_numpy() if 1 in proba.columns else proba.iloc[:, -1].to_numpy()\n",
    "else:\n",
    "    scores = np.asarray(proba)\n",
    "val_scored = val_df.assign(score=scores)\n",
    "metrics = {\n",
    "    \"top1\": top_k_accuracy_at_k(val_scored, \"score\", \"group_id\", \"label\", k=1),\n",
    "    \"top3\": top_k_accuracy_at_k(val_scored, \"score\", \"group_id\", \"label\", k=3),\n",
    "    \"MRR\": mean_reciprocal_rank(val_scored, \"score\", \"group_id\", \"label\"),\n",
    "    \"MAP\": mean_average_precision(val_scored, \"score\", \"group_id\", \"label\"),\n",
    "    \"NDCG@3\": ndcg_at_k(val_scored, \"score\", \"group_id\", \"label\", k=3),\n",
    "}\n",
    "display(pd.Series(metrics))\n",
    "val_scored.sort_values([\"group_id\", \"score\"], ascending=[True, False]).head(10)\n",
    "val_scored.to_csv(OUTDIR / \"val_scored_rows.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 推論 (Top-k 候補出力)\n",
    "\n",
    "- 全充電イベントに対し、候補クラスタの上位 Top-k (スコア付き) を出力\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group_id</th>\n",
       "      <th>hashvin</th>\n",
       "      <th>charge_cluster</th>\n",
       "      <th>ranked_candidates</th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hv_0001_demo__2025-09-02T18:30:00</td>\n",
       "      <td>hv_0001_demo</td>\n",
       "      <td>505</td>\n",
       "      <td>101,202</td>\n",
       "      <td>1.000000,0.003333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hv_0001_demo__2025-09-03T18:45:00</td>\n",
       "      <td>hv_0001_demo</td>\n",
       "      <td>505</td>\n",
       "      <td>101,202</td>\n",
       "      <td>1.000000,0.003333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hv_0001_demo__2025-09-04T18:30:00</td>\n",
       "      <td>hv_0001_demo</td>\n",
       "      <td>606</td>\n",
       "      <td>101,202</td>\n",
       "      <td>1.000000,0.016667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hv_0001_demo__2025-09-05T18:30:00</td>\n",
       "      <td>hv_0001_demo</td>\n",
       "      <td>505</td>\n",
       "      <td>101,202</td>\n",
       "      <td>1.000000,0.003333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hv_0001_demo__2025-09-06T14:30:00</td>\n",
       "      <td>hv_0001_demo</td>\n",
       "      <td>606</td>\n",
       "      <td>101,202</td>\n",
       "      <td>0.990000,0.060000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>hv_0001_demo__2025-09-07T12:45:00</td>\n",
       "      <td>hv_0001_demo</td>\n",
       "      <td>505</td>\n",
       "      <td>101,202</td>\n",
       "      <td>0.993333,0.040000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>hv_0001_demo__2025-09-09T20:15:00</td>\n",
       "      <td>hv_0001_demo</td>\n",
       "      <td>505</td>\n",
       "      <td>101,202</td>\n",
       "      <td>0.980000,0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>hv_0001_demo__2025-09-10T19:00:00</td>\n",
       "      <td>hv_0001_demo</td>\n",
       "      <td>505</td>\n",
       "      <td>101,202</td>\n",
       "      <td>0.996667,0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>hv_0001_demo__2025-09-11T18:45:00</td>\n",
       "      <td>hv_0001_demo</td>\n",
       "      <td>505</td>\n",
       "      <td>101,202</td>\n",
       "      <td>1.000000,0.003333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>hv_0001_demo__2025-09-12T20:45:00</td>\n",
       "      <td>hv_0001_demo</td>\n",
       "      <td>505</td>\n",
       "      <td>101,202</td>\n",
       "      <td>0.980000,0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            group_id       hashvin  charge_cluster  \\\n",
       "0  hv_0001_demo__2025-09-02T18:30:00  hv_0001_demo             505   \n",
       "1  hv_0001_demo__2025-09-03T18:45:00  hv_0001_demo             505   \n",
       "2  hv_0001_demo__2025-09-04T18:30:00  hv_0001_demo             606   \n",
       "3  hv_0001_demo__2025-09-05T18:30:00  hv_0001_demo             505   \n",
       "4  hv_0001_demo__2025-09-06T14:30:00  hv_0001_demo             606   \n",
       "5  hv_0001_demo__2025-09-07T12:45:00  hv_0001_demo             505   \n",
       "6  hv_0001_demo__2025-09-09T20:15:00  hv_0001_demo             505   \n",
       "7  hv_0001_demo__2025-09-10T19:00:00  hv_0001_demo             505   \n",
       "8  hv_0001_demo__2025-09-11T18:45:00  hv_0001_demo             505   \n",
       "9  hv_0001_demo__2025-09-12T20:45:00  hv_0001_demo             505   \n",
       "\n",
       "  ranked_candidates             scores  \n",
       "0           101,202  1.000000,0.003333  \n",
       "1           101,202  1.000000,0.003333  \n",
       "2           101,202  1.000000,0.016667  \n",
       "3           101,202  1.000000,0.003333  \n",
       "4           101,202  0.990000,0.060000  \n",
       "5           101,202  0.993333,0.040000  \n",
       "6           101,202  0.980000,0.000000  \n",
       "7           101,202  0.996667,0.000000  \n",
       "8           101,202  1.000000,0.003333  \n",
       "9           101,202  0.980000,0.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved: outputs\\ranking_demo\\predictions_topk.csv\n"
     ]
    }
   ],
   "source": [
    "top_k = 3\n",
    "proba_all = predictor.predict_proba(df_rank[features])\n",
    "scores_all = (\n",
    "    proba_all[1].to_numpy()\n",
    "    if isinstance(proba_all, pd.DataFrame) and 1 in proba_all.columns\n",
    "    else (\n",
    "        proba_all.iloc[:, -1].to_numpy()\n",
    "        if isinstance(proba_all, pd.DataFrame)\n",
    "        else np.asarray(proba_all)\n",
    "    )\n",
    ")\n",
    "scored_all = df_rank.assign(score=scores_all)\n",
    "rows = []\n",
    "for gid, g in scored_all.groupby(\"group_id\"):\n",
    "    gg = g.sort_values(\"score\", ascending=False).head(top_k)\n",
    "    rows.append(\n",
    "        {\n",
    "            \"group_id\": gid,\n",
    "            \"hashvin\": gg[\"hashvin\"].iloc[0],\n",
    "            \"charge_cluster\": gg[\"charge_cluster\"].iloc[0],\n",
    "            \"ranked_candidates\": \",\".join(map(str, gg[\"candidate_cluster\"].tolist())),\n",
    "            \"scores\": \",\".join(f\"{s:.6f}\" for s in gg[\"score\"].tolist()),\n",
    "        }\n",
    "    )\n",
    "pred_topk = pd.DataFrame(rows)\n",
    "display(pred_topk.head(10))\n",
    "pred_topk.to_csv(OUTDIR / \"predictions_topk.csv\", index=False)\n",
    "print(\"saved:\", OUTDIR / \"predictions_topk.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16bc46a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}