## 1. 推論場所について（ECU vs クラウド）

### 1-1. ECU（車載側）での推論

**通信性**

- ECU 内で完結するため、基本的に **通信がなくても推論可能**。
- トンネル・山間部・地下駐車場など、セルラーが不安定でも動作する。
- AWS IoT Greengrass のドキュメントでも、「クラウドで学習したモデルをエッジに配布し、ローカルデータで推論することで、低レイテンシとコスト削減の恩恵を得られる」と説明されている。  

**レイテンシ**

- センサが載っている車両内部で処理するため、**ms〜十数 ms 程度の非常に小さい遅延**で推論可能。
- IoT/エッジの総論でも、「エッジはクラウドの遅延・帯域・セキュリティ上の制約を補うために生まれた。リアルタイム応答や低レイテンシ用途に向く」と整理されている。  

**コスト**

- ECU 側は、主に **初期コスト（BOM コスト＋開発コスト）に効く**構造。
  - より高性能な SoC（CPU/GPU/NPU）やメモリ、フラッシュ容量が必要。
  - OTA 更新・セキュリティ（署名・暗号化など）も含めた車載 SW 開発のコストが増える。
- 一方で、クラウドに対して常時テレマティクス送信をしない構成にできれば、**通信費・クラウド費用の削減余地**がある。
- McKinsey の自動車コンピューティングに関するレポートでも、「オンボードコンピューティングの高度化に伴い ECU/SoC コストが増加している一方、クラウドとエッジを組み合わせることで帯域とクラウドコストを抑えられる」とされている。  

**計算リソース**

- 走行制御・ADAS 等、他の機能とリソースを共有するため、**専有できる CPU/GPU は限定的**。
- Synaptics や AWS Greengrass の資料でも、「エッジデバイスは低消費電力・小メモリが前提であり、モデル圧縮や軽量化を前提に設計すべき」とされている。  

**その他（運用・プライバシ）**

- モデル更新には OTA が必要で、数万〜十万台規模になると「配布 → 安全確認 → ロールバック」の運用が重くなる。これは Greengrass/Edge Manager のドキュメントでも、フリート運用を前提とした仕組みが別途提供されていることからも読み取れる。  
- データを車外に出さずに処理すれば、走行履歴・位置情報のプライバシ保護には有利。Edge vs Cloud の比較論文でも、「エッジはプライバシと低遅延に強く、クラウドはスケーラビリティと柔軟性に強い」と整理されている。  

---

### 1-2. クラウド（AWS／SageMaker 等）での推論

**通信性**

- 基本的に、車両 or モバイルアプリ → インターネット → AWS リージョン という経路で API を呼び出す構成。
- そのため **通信前提**であり、電波状態・ネットワーク障害の影響を受ける。
- IoT のアーキテクチャ解説でも、「クラウド単独構成は中央集約・分析には優れるが、ネットワーク遅延と帯域制限を受ける」と繰り返し指摘されている。  

**レイテンシ**

- SageMaker のリアルタイム推論は「リアルタイム・インタラクティブ・低レイテンシ用途向け」と公式に定義されているが、これは**クラウド内部の推論処理時間**の話であり、ネットワーク往復遅延は別に乗る。  
- AWS ドキュメントでは、アプリケーション遅延は「インフラのオーバーヘッド＋モデル推論時間＋ネットワーク」の合計だと説明されており、PrivateLink 等でオーバーヘッドを減らしても、物理距離による遅延は残るとされている。  

**コスト**

- **運用コスト（OpEx）側**に効く構造。
  - SageMaker リアルタイムエンドポイント：インスタンス稼働時間＋リクエスト数で課金。  
  - SageMaker Serverless Inference：リクエストごとに「実行時間（ms）×メモリ量」「転送データ量」で課金され、アイドル時はゼロにできる。  
  - Lambda：同様にリクエスト数と実行時間、メモリで課金（INIT/コールドスタートも課金対象であることが明示されている）。  
- ブログ等でも、「常時起動エンドポイント → Serverless に切り替えることで 30〜40% コスト削減できた」事例が紹介されている。  

**計算リソース**

- SageMaker では各種 CPU/GPU インスタンスを選択でき、大規模モデルや高スループット処理も対応可能。  
- オートスケーリング・マルチ AZ などにより、可用性とスケーラビリティを確保しやすい。

**その他（運用・プライバシ）**

- モデルのバージョン管理・AB テスト・ロールバックなどの MLOps 機能はクラウド側に集約しやすく、SageMaker Model Registry 等がそのために提供されている。  
- 一方で、走行ログ・位置情報をクラウドに送る以上、GDPR など各地域のプライバシ規制・データレジデンシに配慮が必要。エッジ vs クラウドの総論論文でもその点が強調されている。  

---

## 2. 推論手法について（クラウド × ECU マトリクス）

まず「どこで実装し得るか」のざっくりマッピングです。

| 推論手法             | クラウド                      | ECU                             |
|----------------------|------------------------------|---------------------------------|
| リアルタイム推論     | 〇（常時起動 Endpoint / API）| 〇（ローカル推論）             |
| バッチ推論           | 〇（Batch Transform など）   | △（1台内の小規模バッチ）      |
| ストリーミング推論   | 〇（Kinesis 等との連携）     | 〇（センサ逐次処理）          |
| サーバレス推論       | 〇（Serverless, Lambda 等）  | －（Greengrass イベント駆動で類似構成） |

SageMaker 公式が、「リアルタイム」「バッチ」「サーバレス」「非同期」等を標準オプションとして整理しているので、ここをベースに考えている。  

---

### 2-1. リアルタイム推論

**クラウド側**

- SageMaker リアルタイムエンドポイント：  
  「リアルタイム・インタラクティブ・低レイテンシ要求向け」で、REST API として常時待ち受ける形。  
- 特徴
  - 長時間の安定トラフィックがある場合に向く。
  - オートスケーリングを組めば、ピークに応じてインスタンス数を増やせる。
  - 一方、アイドル時間もインスタンス課金が発生する。

**ECU側**

- 車内での推論は本質的に「リアルタイム推論」。
  - 走行中の残 SOC に応じた判断
  - 急な充電ニーズの即時計算
- Greengrass + Edge Manager などで、クラウド学習モデルをローカルで推論する構成が AWS から公式に示されている。  

---

### 2-2. バッチ推論

**クラウド側**

- SageMaker Batch Transform：大量データの一括推論に特化した仕組み。  
- 特徴
  - 1 日 1 回・数時間ごとに全ユーザー分を一気にスコアリングするのに適している。
  - 夜間などのオフピーク時間に実行し、コスト・スループットを両立しやすい。
  - 推論結果を DB/ストレージに保存し、アプリからは「読むだけ」にできる。

**ECU側**

- 1 台分のログに対して、駐車中に「1 日の振り返り」をローカルバッチする程度なら現実的。
- ただし、「10 万ユーザー分の一括計算」はクラウド側の責務であり、車載側は本質的にスケールアウトできない点がクラウドとの違い。

---

### 2-3. ストリーミング推論

**クラウド側**

- 全車からの SOC・位置などを Kinesis などにストリームとして集約し、  
  Lambda / Kinesis Data Analytics / SageMaker と組み合わせて逐次推論する形が一般的。  
- EV 以外でも、IoT での異常検知・予知保全で頻出のパターン。

**ECU側**

- CAN バスや BMS からのセンサ値を連続的に監視し、閾値やモデルで逐次判定。
- 「毎サンプルごとに判定 → 即反応」が必要な機能（安全寄り）は ECU ストリーミングで処理し、ログは後でクラウドに送る、という役割分担が多い。  

---

### 2-4. サーバレス推論（クラウドのみ）

**クラウド側**

- SageMaker Serverless Inference / AWS Lambda:
  - 「トラフィックが疎で、ピークが読みづらく、アイドルコストを抑えたい」用途向け、と AWS 公式・ブログで説明されている。  
- 特徴
  - 使った分だけ課金。  
  - コールドスタート遅延（起動に数百 ms〜数秒）があり、「ユーザーが体感する応答時間として許容できるか」が導入条件。  

**ECU側**

- 「サーバレス」というマネージドサービスはないが、Greengrass 上でイベントトリガでコンポーネント／Lambda を起動する構成により、「擬似サーバレス」的な動かし方は可能。  

---

## 3. 想定される推論タイミングと対応する手法

ここからが本プロジェクトに直結する部分。  
ケースごとに、「どこで」「どの手法」が自然かを整理します。

---

### 3-1. 朝一定期リコメンド（朝一の「今日のおすすめ」）

- **目的**
  - 「今日の帰宅時ターゲット SOC」「今晩の充電をスキップして良いか」などを毎朝提示。

- **推奨構成**
  - **クラウド × バッチ推論**
    - 夜間〜早朝に SageMaker Batch Transform や Processing Job で、全ユーザー分を一括スコアリング。  
    - 結果を DB に保存し、朝アプリを開いたときには即時に結果を表示。

- **理由**
  - 即時性より **スループットとコスト効率**が重要。
  - フリート全体での統計・分析も同時にできるので、サービス改善にも寄与。

- **ECU案**
  - 各車両がローカルに「今日のおすすめ」を計算することも理論的には可能だが、
    - 分析性・モデル更新・AB テスト
  - を考えるとクラウド側バッチが圧倒的に運用しやすいため、机上では優先度低の案と位置付けてよい。

---

### 3-2. 推奨充電タイミング前のリマインド推論

- **目的**
  - 「いつも 22:00 に自宅充電するユーザー」に対して、21:30 に
    - 「今日の推奨充電有無・推奨 SOC」
  - を通知する。

- **候補案**
  1. **朝バッチで計算済み → リマインドは通知だけ**
     - 朝のバッチ推論で「本日 22:00 充電予定＋今日の推奨値」を計算し、  
       21:30 にはその内容を push 通知するだけ。
  2. **リマインド直前にサーバレス推論**
     - EventBridge 等で 21:30 にジョブを起動し、そのタイミングで Serverless Endpoint or Lambda で最新状態を含めて推論。  

- **机上での結論**
  - 「直前に電気料金や天気など、追加情報を取り込みたいか」で選択が変わる。
  - 現時点（電力料金・外部要素をそこまで使わない前提）なら、**朝バッチ＋リマインド通知のみ**がシンプルで良さそう。
  - PoC 結果として「直前の情報を加味したい」という要件が出れば、「サーバレス推論追加」を第二ステップとして検討する方針でよい。

---

### 3-3. 充電前の突発リコメンド

- **目的**
  - 普段と違うタイミング・場所で充電しようとしたユーザーに対し、その場で推奨充電量・スキップ可否を返す。

- **トリガ例**
  - モバイルアプリの「今から充電、推奨量を教えて」ボタン押下。
  - 充電プラグ IN の検知。
  - 急速充電ステーションエリアへのジオフェンス侵入。

- **クラウド案：リアルタイム推論**
  - アプリ or 車載からクラウド API（SageMaker リアルタイム or Lambda）を呼び出し、1〜数秒で結果を返す。  

- **ECU案：リアルタイム推論**
  - 車両側で完結。
  - 通信圏外でも表示できるが、モデルの更新・高度な特徴量（外部情報）が使いにくい。

- **机上での整理**
  - 「どこで UX を中心に設計するか」で決まる。
    - アプリ中心 → クラウドリアルタイムが自然。
    - 車載ナビ中心 → ECUリアルタイムが自然。
  - 管理コストを考えると、**初期はクラウド側で統一し、ECU は将来の選択肢として保持**というステップ設計が現実的。

---

### 3-4. SOC が下限値を下回ったケース（SOC 10% 未満など）

- **目的**
  - 残量が危険域に入ったときに、「本当にいつもの充電ポイントまで到達できるか」を即座に評価して警告・提案したい。

- **検知 × 推論の分離**

  - **検知**：SOC が 10% を下回ったことを検知するのは ECU（BMS）で行うのが自然。
  - そこからの **推論の場所**は、設計方針によって分かれる。

- **パターン A：ECU 内で検知＆推論**
  - 完全オフラインでも安全機能を提供できる。
  - レイテンシ最小で、運転者への警告・ルート再計算などに向く。

- **パターン B：ECU で検知 → クラウドにリアルタイム API を投げる**
  - 「ECU で低下を検知し、そのイベントをクラウド API に投げてリアルタイム推論」も構成としては可能。
  - ただし、
    - 通信状況によっては応答が遅れる／返ってこない。
    - 安全に直結する判断をクラウド依存にするリスク。
  - があるため、**安全度の高い機能（到達不能リスク警告など）は、最終的には ECU 側で完結させる案が望ましい**と考えられる。  
    一方で、「そこまで緊急ではない補助的なアドバイス」であればクラウドリアルタイムも選択肢になる。

- **机上の結論**
  - このケースは、「機能の安全度クラス」が確定しないと最終判断ができない。
  - 方針としては：
    - 安全度 A（到達可能性に直接関わる） → **ECU推論を第1候補**。
    - 安全度 B（参考アドバイスレベル） → 「ECU検知＋クラウドリアルタイム」も検討対象に残す。

---

### 3-5. SOC が予測ラインより〇% 低下した場合の再推論

- **目的**
  - 事前に予測した SOC 軌跡から大きく外れた時に、計画を見直して再提案したい。

- **緊急度による整理**

1. **高緊急（このままだと到達不能リスクが高まりつつある）**
   - 検知・推論ともに ECU ストリーミングで行うのが筋。
   - 継続的に SOC と距離・ルートを評価し続ける構成。

2. **中〜低緊急（到達はできそうだが余裕が減ってきた）**
   - 一定間隔でクラウドにログを送信し、サーバレス推論で「最新の計画を更新」する構成もあり得る。
   - ここは「コールドスタートを UX 的に許容できるか」がサーバレス採用の鍵。  

---

## 4. 机上段階の対応方針（＝最終構成を決めるために何をするか）

ここは「最終構成そのもの」ではなく、**最終構成を決めるために必要な検討・比較項目**を定義する場所、と位置づける。

大きく以下の 4 ブロックに分けられる。

### 4-1. UX 観点で決めること

1. **ユースケースごとの UX 要件整理**
   - 朝定期リコメンド
   - 充電前突発リコメンド
   - リマインド
   - SOC 下限・予測逸脱時の警告
   など、それぞれについて：
   - どこでユーザーが結果を見るのか（アプリ／車載ナビ／メール）。
   - ユーザーがどれくらい待てるか（許容レイテンシ目標：例 0.1s / 1s / 5s）。
   - オフライン時の期待値（「通信がなくても最低限これだけは動いてほしい」）。

2. **オフライン要件の整理**
   - 停電・通信断時にも絶対に動かしたい機能（安全寄り）。
   - 通信があれば便利だが、なくても致命的ではない機能（快適性寄り）。

→ これにより、「UX 要件から見た ECU/クラウドの優先度」が決められる。

---

### 4-2. コスト・非機能要件（スケーラビリティ）で決めること

1. **クラウド案の概算コストモデル作成**
   - パターン例：
     - クラウド・バッチ＋クラウド・リアルタイム
     - クラウド・バッチ＋サーバレス
   - 前提として、
     - 1 ユーザーあたりの推論回数／日（朝定期 1 回＋突発 0.数回など）
     - ピーク時 QPS（例：夜間に集中する など）
   - を仮置きし、SageMaker リアルタイム／Serverless の料金モデルを使ってレンジ試算。  

2. **ECU 案の概算コストモデル作成**
   - ECU SoC・メモリ・フラッシュのグレードアップ分の BOM コスト増。
   - Edge Manager / Greengrass を使う場合のライセンス・運用コスト。  

3. **スケーラビリティ・運用負荷の評価**
   - クラウド案では、10 万ユーザー規模でのオートスケーリング・マルチ AZ・監視設計。
   - ECU 案では、10 万台への OTA 配信・バージョン管理・不具合時ロールバック手順。

→ コストと運用性の観点から、「クラウド案」「ECU案」「限定ハイブリッド案」の優劣を比較するのが対応方針になる（ML の予測精度とは独立）。

---

### 4-3. 技術的制約・実現可能性を確認すること

1. **ECU のベンチマーク**
   - 想定される ECU スペックに対して、ターゲットモデル（ONNX など）の推論時間・メモリ使用量を測定。
   - とくに SOC 下限・ストリーミング用途で必要な最大レイテンシと比較。

2. **ネットワークレイテンシ・可用性の測定**
   - 日本／北米／欧州の代表エリアで、
     - 車両 or モバイルから AWS リージョンまでの RTT 分布を測る（LTE/5G 前提）。
   - 「実際の分布」を見て、クラウドリアルタイムで UX 的に許容されるかを検証。

3. **データ量・帯域の評価**
   - 送信するテレマティクスの粒度（5 分単位かイベントのみか）によって、  
     帯域コストとバッチ/ストリーミング構成が変わる。

---

### 4-4. 比較・意思決定プロセスの定義

机上段階で明文化しておくと良さそうな「意思決定のステップ」は例えば次のような形。

1. **ユースケース × 緊急度 × UX 要件 マトリクスの確定**
2. **クラウド案・ECU案・限定ハイブリッド案の 3 パターン定義**
3. **各パターンについて、非機能（レイテンシ／可用性／運用性／コスト）のスコアリング**
4. **事業側と合意のうえ、「初期リリース構成」と「将来拡張の方向性」を決定**

ここまでが「机上段階の対応方針」として顧客に出せるメッセージになる。

---

## 5. 結論（現時点のまとめ）

- 推論場所（ECU vs クラウド）と推論手法（リアルタイム／バッチ／ストリーミング／サーバレス）について、  
  一般論＋EV 文脈での特徴・適用シーンを整理した。
- 今回のリコメンドユースケースに当てはめると：
  - 朝定期リコメンド → クラウド・バッチ推論が第 1 候補。
  - 充電前突発・リマインド → クラウド・リアルタイム or サーバレスが主。
  - SOC 下限・予測逸脱 → 検知は必ず ECU、推論は安全度に応じて ECU or クラウド。
- PoC フェーズでは、
  - **推論場所や手法そのものを決め切ること**よりも、
  - **UX と非機能要件（レイテンシ・コスト・運用）の観点から、最終構成を決めるために必要な情報と比較軸を定義すること**が重要。
- ML モデルの予測精度は、もちろん全体の価値を左右するものの、
  - 「クラウドに置くか ECU に置くか」
  - 「リアルタイムで呼ぶかバッチにするか」
  は基本的に **別次元の設計問題**であり、今回の整理は主に後者（推論アーキテクチャ）の話にフォーカスしている。

---

## 6. 未確定事項・今後の課題リスト（整理版）

1. ECU の実際のスペック（CPU/GPU/NPU、メモリ、ストレージ）と、それに対するモデルの推論ベンチマーク。
2. 日本・北米・欧州などでのモバイル→AWS リージョン間レイテンシ分布と、クラウドリアルタイム推論で許容できる UX の範囲。
3. 1 ユーザーあたりの想定推論回数／日・ピークパターンを仮置きしたうえでの、クラウド案の概算コストモデル。
4. ECU にモデルを載せる場合の BOM 増加・OTA 運用コストの概算。
5. 各ユースケースの緊急度ランク（安全度 A/B）と、それに応じた「ECU 必須かどうか」の整理。
6. 地域ごとのデータレジデンシ・プライバシ規制（GDPR 等）に基づく、クラウド側データ設計。
7. ONNX などのモデルフォーマット・量子化・Edge Manager/Neo 等を使うかどうかの技術選定。
8. クラウド案／ECU案／限定ハイブリッド案の 3 パターンについて、事業側を含めた比較評価プロセスの具体的な進め方。

---

## 7. 参考文献と参照内容

※「何がまとまっているページか」「本文のどの論点で参照したか」を簡潔に記載。

1. **Amazon SageMaker リアルタイム推論**  
   - URL: https://docs.aws.amazon.com/sagemaker/latest/dg/realtime-endpoints.html   
   - 内容: SageMaker のリアルタイムエンドポイントの概要。低レイテンシ・インタラクティブ用途向けで、常時起動 REST API として提供されることが説明されている。  
   - 使用箇所: 「クラウド × リアルタイム推論」の定義・用途、「推論手法」の整理。

2. **Amazon SageMaker Serverless Inference**  
   - URL: https://docs.aws.amazon.com/sagemaker/latest/dg/serverless-endpoints.html   
   - 内容: Serverless Inference の概要・料金モデル・コールドスタートの注意点。  
   - 使用箇所: 「サーバレス推論」の特徴（疎なトラフィック向け／コールドスタートあり）、「リマインド直前推論」などサーバレス候補案の説明。

3. **AWS Lambda Pricing & Cold Start 関連**  
   - URL: https://aws.amazon.com/lambda/pricing/   
   - 内容: Lambda の課金モデル（リクエスト数・実行時間・メモリ）、INIT フェーズ（コールドスタート）も課金対象であることなど。  
   - 使用箇所: サーバレス推論のコスト構造・コールドスタート説明。

4. **AWS IoT Greengrass – 機械学習推論**  
   - URL: https://docs.aws.amazon.com/greengrass/v2/developerguide/perform-machine-learning-inference.html   
   - 内容: Greengrass でクラウド学習モデルをエッジにデプロイし、ローカルデータで推論を行う方法。必要なストレージ・コンポーネント構成など。  
   - 使用箇所: ECU 側でのローカル推論の一般的なパターン、モデル配布・運用の難しさの背景説明。

5. **Edge Computing / Edge AI 総論（IoT 文脈）**  
   - URL: https://www.synaptics.com/company/blog/iot-edge-computing-ml   
   - 内容: エッジコンピューティングがクラウドだけの構成に比べて、レイテンシ・帯域・セキュリティの課題をどう補うか、IoT デバイス向けの設計指針。  
   - 使用箇所: 「ECU の特性（低レイテンシ・帯域節約・プライバシ）」の説明。

6. **Cloud vs Edge in IoT（ハイブリッドの整理）**  
   - URL: https://www.mdpi.com/2227-9709/11/4/71   
   - 内容: Edge はレイテンシ削減とプライバシに強く、クラウドはスケーラビリティと柔軟性に強いという比較。ハイブリッドアーキテクチャの有効性も論じている。  
   - 使用箇所: ECU vs クラウドの総論、および「限定的ハイブリッド案」をオプションとして扱う理由付け。

7. **McKinsey – Automotive Computing / Edge AI**  
   - URL: https://www.mckinsey.com/industries/semiconductors/our-insights/the-future-of-automotive-computing-cloud-and-edge   
   - 内容: 自動車コンピューティングにおけるクラウドとエッジの役割分担、ECU/SoC コスト増、5G・エッジ AI の潮流。  
   - 使用箇所: 「ECU 側のコスト増」「安全関連はエッジ側が重要になる」といった文脈。

8. **SageMaker Edge Manager + Greengrass 連携ブログ**  
   - URL: https://aws.amazon.com/blogs/machine-learning/build-machine-learning-at-the-edge-applications-using-amazon-sagemaker-edge-manager-and-aws-iot-greengrass-v2/   
   - 内容: モデルをクラウドで学習・最適化し、Greengrass 経由でエッジに配布・推論する一連のフロー。  
   - 使用箇所: ECU にモデルを載せるときの OTA／フリート運用のイメージと、その複雑さの背景。

9. **SageMaker Inference オプションの概要**  
   - URL: https://aws.amazon.com/sagemaker/ai/deploy/   
   - 内容: SageMaker のデプロイオプション（リアルタイム・バッチ・サーバレス・非同期）の整理。  
   - 使用箇所: 「推論手法」の体系的な整理（クラウド側オプションの定義）に利用。

# EVバッテリ劣化抑制ソリューション アーキテクチャ検討レポート

## 1. はじめに

本ドキュメントは、機械学習を用いた「最適SOC誘導型バッテリ劣化抑制ソリューション」の実現に向けたアーキテクチャ設計の検討結果をまとめたものである。
本プロジェクトはPoC（概念実証）フェーズにあり、最終的な商用サービス化を見据えつつ、実現可能性、ビジネスインパクト、運用コストの観点から最適な推論配置（ECU vs クラウド）を決定する必要がある。

本レポートでは、一般的な技術特性の整理から始まり、本ソリューションにおける具体的な実装パターンの評価、そして最終構成を決定するための判断フレームワークを提示する。

---

## 2. 推論配置における技術特性の体系的整理

アーキテクチャ選定の基礎として、推論環境（クラウド vs エッジ/ECU）ごとの技術的特性を整理する。

| 観点 | クラウド推論 (Cloud Inference) | エッジ/ECU推論 (Edge Inference) | 参照ソース・根拠 |
| :--- | :--- | :--- | :--- |
| **計算資源** | **大・可変**<br>GPU等の強力なリソースを利用可能。需要に応じたスケーリングが容易である。 | **小・固定**<br>ECUのスペック（CPU/NPU/メモリ）に厳格に制限される。 | **[AWS SageMaker Docs](https://docs.aws.amazon.com/sagemaker/latest/dg/realtime-endpoints.html)**<br>クラウドの伸縮性とインスタンス選択の自由度について言及されている。 |
| **レイテンシ** | **中～大 (ネットワーク依存)**<br>通信往復時間(RTT)が発生する。電波状況に左右されるため変動幅が大きい。 | **極小 (リアルタイム)**<br>データ発生源で処理するため、ms単位の安定した応答が可能である。 | **[Synaptics Edge AI Blog](https://www.synaptics.com/company/blog/iot-edge-computing-ml)**<br>エッジコンピューティングがクラウドのレイテンシと帯域幅の課題を解決する点について解説されている。 |
| **可用性** | **通信依存**<br>トンネル、地下、山間部などの圏外や通信障害時は機能しない。 | **高 (スタンドアロン)**<br>通信環境に関わらず動作可能であるため、安全機能に適している。 | **[McKinsey Automotive Cloud/Edge](https://www.mckinsey.com/industries/semiconductors/our-insights/the-future-of-automotive-computing-cloud-and-edge)**<br>自動運転や安全機能など「停止が許されない機能」はエッジ必須であるとの論拠。 |
| **運用・更新** | **容易**<br>サーバー側のデプロイのみで全ユーザーに即時適用可能である。 | **困難・高コスト**<br>OTA (Over-The-Air) が必要となる。数万台規模への配布・検証・ロールバックの運用コストが高い。 | **[AWS IoT Greengrass Docs](https://docs.aws.amazon.com/greengrass/v2/developerguide/perform-machine-learning-inference.html)**<br>エッジへのモデル配布・管理（フリート管理）の複雑さと、それを解決する仕組みの必要性について記述されている。 |
| **プライバシ** | **データ転送必須**<br>位置情報等の生データを外部に出すためのセキュリティ設計および法令対応（GDPR等）が必要。 | **ローカル完結**<br>生データを出さず、推論結果のみを扱うことが可能である。 | **[Research: Edge vs Cloud](https://www.mdpi.com/2227-9709/11/4/71)**<br>プライバシ規制下においてエッジ処理がデータ保護の観点で有利である点について論じられている。 |

---

## 3. 推論配置パターンの定義

本ソリューションにおいて比較検討すべきアーキテクチャは、ハイブリッド（動的切り替え）ありきではなく、管理コストと特性の明確化のために以下の3パターンに集約される。

### パターンA：クラウド完結 (Cloud Only)
* **概要**: 学習・推論のすべてをクラウド（AWS SageMaker等）で行う。車両はセンサーデータを送信し、推論結果（推奨充電プラン）を受信するシンクライアント構成。
* **特徴**: モデル更新頻度が高い初期段階や、外部データ連携が必要な場合に有利。通信断時は機能しない。

### パターンB：ECU完結 (Edge Only)
* **概要**: クラウドで学習したモデルをECUへ配布し、推論は車両内で完結させる。
* **特徴**: 通信不要で常時動作し、レスポンスが高速。ただし、ECUリソース制限によりモデルサイズに制約があり、モデル更新の運用負荷が高い。

### パターンC：機能分担 (Static Split)
* **概要**: ユースケースごとに配置を固定する。
    * 重い処理（定期計画作成） → クラウド
    * 即応処理（緊急判定） → ECU
* **特徴**: 両者のメリットを享受できるが、「2つの推論環境の保守」「ロジックの不整合管理」という複雑さと二重コストが発生する。

---

## 4. 推論トリガごとの評価マトリクス

各ユースケース（トリガ）に対し、3つのパターンを5つの基準で評価した。

**評価凡例**: ◎: 最適 / ◯: 適合 / △: 課題あり / ×: 不向き

| トリガ (Use Case) | 評価基準 (Criteria) | パターンA<br>クラウド完結 | パターンB<br>ECU完結 | パターンC<br>機能分担 | 評価・判断理由の詳細 |
| :--- | :--- | :--- | :--- | :--- | :--- |
| **① 定期リコメンド**<br>(翌日の充電計画) | **精度・情報量**<br>(外部データ連携) | **◎** | △ | **◎** | **A/C有利**: 翌日の計画には「天気予報」「電力需給」「他ユーザーの傾向」など、クラウド上の最新情報が必須である。ECU単独ではこれらの動的な外部情報をリアルタイムに取り込む仕組みが複雑化するため、クラウド処理が合理的である。 |
| | **運用コスト**<br>(通信・計算) | **◎** | ◯ | **◎** | **A/C有利**: 夜間に「Batch Transform」等でまとめて計算することで、クラウドコストを最小化できる。ECUの場合、計算のために個々の車両を起動する必要があり、暗電流や電力消費の観点で非効率となる可能性がある。 |
| **② 突発リコメンド**<br>(直前の充電可否) | **即時性**<br>(レイテンシ) | ◯ | **◎** | ◯ | **B有利**: ECUはmsオーダーで応答可能である。一方、クラウドは通信往復を含め数秒かかるが、人間がアプリを操作して結果を待つユースケース（数秒の待機は許容される）であれば、A/Cでも実用上の問題はない。 |
| | **可用性**<br>(通信断時の動作) | △ | **◎** | △ | **B有利**: 地下駐車場などで通信が繋がらない場合、AおよびC（クラウド側機能）は動作しない。ここを「仕様（圏外では利用不可）」とするか、「必須要件」とするかがアーキテクチャ決定の分かれ目となる。 |
| **③ 緊急判定**<br>(SOC下限/乖離) | **即時性・安全性**<br>(レイテンシ) | △ | **◎** | **◎** | **B/C有利**: 走行中のSOC急減などの緊急判定は、通信遅延や切断が命取りとなる。即座にドライバーへ警告する必要があるため、ECU側での処理が強く推奨される（あるいは必須要件となる可能性が高い）。 |
| | **実装難易度**<br>(開発・更新) | ◯ | △ | △ | **A有利**: ECUへのモデル実装は、メモリ制約への適合（量子化・軽量化）や、OTAによる更新運用など、開発・保守コストが増大する。Cは両方の環境を管理が必要なため、最も管理コストが高い。 |

---

## 5. 最終構成決定のための判断フレームワーク

PoCを通じて以下の「未確定パラメータ」を埋めることで、論理的に最終構成を決定する。

### 5-1. 調査・決定すべき項目（穴埋めリスト）

| 分類 | No. | 検討項目 | 調査・決定すべき問い (Question) | 判定への影響 |
| :--- | :--- | :--- | :--- | :--- |
| **要件** | **Q1** | **許容レイテンシ** | ユーザーは操作後、結果表示まで何秒待てるか？（例：3.0秒） | 1秒未満ならECU必須。3秒以上ならクラウドAPIで可。 |
| **要件** | **Q2** | **オフライン要件** | 圏外での機能不全を許容するか？ | 許容不可ならECU必須。許容ならクラウドでOK。 |
| **要件** | **Q3** | **安全機能の範囲** | SOC下限警告は本AIの責務か、既存BMSの責務か？ | AIが安全責務ならECU必須。助言レベルならクラウド可。 |
| **技術** | **T1** | **モデルサイズ** | ONNX化・量子化後のサイズはECU容量に収まるか？ | 容量超過ならクラウド一択。 |
| **技術** | **T2** | **推論速度(ECU)** | 想定ECUでの推論時間は許容範囲内か？ | 処理落ちするならクラウド一択。 |
| **技術** | **T3** | **通信遅延(RTT)** | 実走行環境（4G/5G）での平均/99%タイル遅延は？ | Q1を満たせなければECU必須。 |

### 5-2. 構成決定ロジック（デシジョンツリー）

上記の調査結果に基づき、以下の優先順位で判断する。

1.  **Safety First (Q3)**: 安全責務があるなら **パターンB or C (ECU機能必須)**。
2.  **Offline UX (Q2)**: 圏外動作が必須なら **パターンB (ECU)**。
3.  **Feasibility (T1, T2)**: ECUリソース不足なら **パターンA (クラウド)**。
4.  **Cost Efficiency**: 上記以外の場合、通信コストと外部データ連携のメリットを比較し、**パターンA** または **パターンC** を選択。

---

## 6. PoCおよび今後のアクションプラン

上記検討を踏まえ、本プロジェクトでは以下のステップで進行する。

### 方針概要
* **PoCフェーズ**: 原則として**「パターンA（クラウド完結）」**を採用する。
    * **理由**: モデルのアルゴリズム改善（精度向上）こそが最大の不確実性であり、デプロイサイクルの速いクラウドでこれを最優先に検証するため。
* **並行検証**: 将来のリスクヘッジとして、ECU実装の技術的実現性（Feasibility）のみ並行して確認を行う。

### 具体的なアクション
1.  **ビジネス要件の仮定義 (Q1〜Q3)**
    * 特に「オフライン時の挙動」と「安全機能の責任分界点」について、事業部および車両開発側と合意形成を図る。
2.  **クラウドベースでのモデル検証 (パターンA)**
    * SageMakerを用いたパイプライン構築。
    * バッチ推論によるコスト試算および精度検証。
3.  **ECU実装性の机上・実機検証 (T1, T2)**
    * 作成したモデルをONNX形式へ変換し、量子化によるサイズ圧縮率と精度劣化を測定する。
    * 開発用ボード等で推論速度をベンチマークし、ECU搭載の可否を判断する材料を揃える。

## 7. 参考文献

1.  **Amazon SageMaker リアルタイム推論** (https://docs.aws.amazon.com/sagemaker/latest/dg/realtime-endpoints.html)
2.  **Synaptics: IoT Edge Computing & ML** (https://www.synaptics.com/company/blog/iot-edge-computing-ml)
3.  **McKinsey: The future of automotive computing** (https://www.mckinsey.com/industries/semiconductors/our-insights/the-future-of-automotive-computing-cloud-and-edge)
4.  **AWS IoT Greengrass: Perform ML Inference** (https://docs.aws.amazon.com/greengrass/v2/developerguide/perform-machine-learning-inference.html)
5.  **MDPI: Cloud vs Edge Computing** (https://www.mdpi.com/2227-9709/11/4/71)

以上


