## 1. 推論場所について（ECU vs クラウド）

### 1-1. ECU（車載側）での推論

**通信性**

- ECU 内で完結するため、基本的に **通信がなくても推論可能**。
- トンネル・山間部・地下駐車場など、セルラーが不安定でも動作する。
- AWS IoT Greengrass のドキュメントでも、「クラウドで学習したモデルをエッジに配布し、ローカルデータで推論することで、低レイテンシとコスト削減の恩恵を得られる」と説明されている。  

**レイテンシ**

- センサが載っている車両内部で処理するため、**ms〜十数 ms 程度の非常に小さい遅延**で推論可能。
- IoT/エッジの総論でも、「エッジはクラウドの遅延・帯域・セキュリティ上の制約を補うために生まれた。リアルタイム応答や低レイテンシ用途に向く」と整理されている。  

**コスト**

- ECU 側は、主に **初期コスト（BOM コスト＋開発コスト）に効く**構造。
  - より高性能な SoC（CPU/GPU/NPU）やメモリ、フラッシュ容量が必要。
  - OTA 更新・セキュリティ（署名・暗号化など）も含めた車載 SW 開発のコストが増える。
- 一方で、クラウドに対して常時テレマティクス送信をしない構成にできれば、**通信費・クラウド費用の削減余地**がある。
- McKinsey の自動車コンピューティングに関するレポートでも、「オンボードコンピューティングの高度化に伴い ECU/SoC コストが増加している一方、クラウドとエッジを組み合わせることで帯域とクラウドコストを抑えられる」とされている。  

**計算リソース**

- 走行制御・ADAS 等、他の機能とリソースを共有するため、**専有できる CPU/GPU は限定的**。
- Synaptics や AWS Greengrass の資料でも、「エッジデバイスは低消費電力・小メモリが前提であり、モデル圧縮や軽量化を前提に設計すべき」とされている。  

**その他（運用・プライバシ）**

- モデル更新には OTA が必要で、数万〜十万台規模になると「配布 → 安全確認 → ロールバック」の運用が重くなる。これは Greengrass/Edge Manager のドキュメントでも、フリート運用を前提とした仕組みが別途提供されていることからも読み取れる。  
- データを車外に出さずに処理すれば、走行履歴・位置情報のプライバシ保護には有利。Edge vs Cloud の比較論文でも、「エッジはプライバシと低遅延に強く、クラウドはスケーラビリティと柔軟性に強い」と整理されている。  

---

### 1-2. クラウド（AWS／SageMaker 等）での推論

**通信性**

- 基本的に、車両 or モバイルアプリ → インターネット → AWS リージョン という経路で API を呼び出す構成。
- そのため **通信前提**であり、電波状態・ネットワーク障害の影響を受ける。
- IoT のアーキテクチャ解説でも、「クラウド単独構成は中央集約・分析には優れるが、ネットワーク遅延と帯域制限を受ける」と繰り返し指摘されている。  

**レイテンシ**

- SageMaker のリアルタイム推論は「リアルタイム・インタラクティブ・低レイテンシ用途向け」と公式に定義されているが、これは**クラウド内部の推論処理時間**の話であり、ネットワーク往復遅延は別に乗る。  
- AWS ドキュメントでは、アプリケーション遅延は「インフラのオーバーヘッド＋モデル推論時間＋ネットワーク」の合計だと説明されており、PrivateLink 等でオーバーヘッドを減らしても、物理距離による遅延は残るとされている。  

**コスト**

- **運用コスト（OpEx）側**に効く構造。
  - SageMaker リアルタイムエンドポイント：インスタンス稼働時間＋リクエスト数で課金。  
  - SageMaker Serverless Inference：リクエストごとに「実行時間（ms）×メモリ量」「転送データ量」で課金され、アイドル時はゼロにできる。  
  - Lambda：同様にリクエスト数と実行時間、メモリで課金（INIT/コールドスタートも課金対象であることが明示されている）。  
- ブログ等でも、「常時起動エンドポイント → Serverless に切り替えることで 30〜40% コスト削減できた」事例が紹介されている。  

**計算リソース**

- SageMaker では各種 CPU/GPU インスタンスを選択でき、大規模モデルや高スループット処理も対応可能。  
- オートスケーリング・マルチ AZ などにより、可用性とスケーラビリティを確保しやすい。

**その他（運用・プライバシ）**

- モデルのバージョン管理・AB テスト・ロールバックなどの MLOps 機能はクラウド側に集約しやすく、SageMaker Model Registry 等がそのために提供されている。  
- 一方で、走行ログ・位置情報をクラウドに送る以上、GDPR など各地域のプライバシ規制・データレジデンシに配慮が必要。エッジ vs クラウドの総論論文でもその点が強調されている。  

---

## 2. 推論手法について（クラウド × ECU マトリクス）

まず「どこで実装し得るか」のざっくりマッピングです。

| 推論手法             | クラウド                      | ECU                             |
|----------------------|------------------------------|---------------------------------|
| リアルタイム推論     | 〇（常時起動 Endpoint / API）| 〇（ローカル推論）             |
| バッチ推論           | 〇（Batch Transform など）   | △（1台内の小規模バッチ）      |
| ストリーミング推論   | 〇（Kinesis 等との連携）     | 〇（センサ逐次処理）          |
| サーバレス推論       | 〇（Serverless, Lambda 等）  | －（Greengrass イベント駆動で類似構成） |

SageMaker 公式が、「リアルタイム」「バッチ」「サーバレス」「非同期」等を標準オプションとして整理しているので、ここをベースに考えている。  

---

### 2-1. リアルタイム推論

**クラウド側**

- SageMaker リアルタイムエンドポイント：  
  「リアルタイム・インタラクティブ・低レイテンシ要求向け」で、REST API として常時待ち受ける形。  
- 特徴
  - 長時間の安定トラフィックがある場合に向く。
  - オートスケーリングを組めば、ピークに応じてインスタンス数を増やせる。
  - 一方、アイドル時間もインスタンス課金が発生する。

**ECU側**

- 車内での推論は本質的に「リアルタイム推論」。
  - 走行中の残 SOC に応じた判断
  - 急な充電ニーズの即時計算
- Greengrass + Edge Manager などで、クラウド学習モデルをローカルで推論する構成が AWS から公式に示されている。  

---

### 2-2. バッチ推論

**クラウド側**

- SageMaker Batch Transform：大量データの一括推論に特化した仕組み。  
- 特徴
  - 1 日 1 回・数時間ごとに全ユーザー分を一気にスコアリングするのに適している。
  - 夜間などのオフピーク時間に実行し、コスト・スループットを両立しやすい。
  - 推論結果を DB/ストレージに保存し、アプリからは「読むだけ」にできる。

**ECU側**

- 1 台分のログに対して、駐車中に「1 日の振り返り」をローカルバッチする程度なら現実的。
- ただし、「10 万ユーザー分の一括計算」はクラウド側の責務であり、車載側は本質的にスケールアウトできない点がクラウドとの違い。

---

### 2-3. ストリーミング推論

**クラウド側**

- 全車からの SOC・位置などを Kinesis などにストリームとして集約し、  
  Lambda / Kinesis Data Analytics / SageMaker と組み合わせて逐次推論する形が一般的。  
- EV 以外でも、IoT での異常検知・予知保全で頻出のパターン。

**ECU側**

- CAN バスや BMS からのセンサ値を連続的に監視し、閾値やモデルで逐次判定。
- 「毎サンプルごとに判定 → 即反応」が必要な機能（安全寄り）は ECU ストリーミングで処理し、ログは後でクラウドに送る、という役割分担が多い。  

---

### 2-4. サーバレス推論（クラウドのみ）

**クラウド側**

- SageMaker Serverless Inference / AWS Lambda:
  - 「トラフィックが疎で、ピークが読みづらく、アイドルコストを抑えたい」用途向け、と AWS 公式・ブログで説明されている。  
- 特徴
  - 使った分だけ課金。  
  - コールドスタート遅延（起動に数百 ms〜数秒）があり、「ユーザーが体感する応答時間として許容できるか」が導入条件。  

**ECU側**

- 「サーバレス」というマネージドサービスはないが、Greengrass 上でイベントトリガでコンポーネント／Lambda を起動する構成により、「擬似サーバレス」的な動かし方は可能。  

---

## 3. 想定される推論タイミングと対応する手法

ここからが本プロジェクトに直結する部分。  
ケースごとに、「どこで」「どの手法」が自然かを整理します。

---

### 3-1. 朝一定期リコメンド（朝一の「今日のおすすめ」）

- **目的**
  - 「今日の帰宅時ターゲット SOC」「今晩の充電をスキップして良いか」などを毎朝提示。

- **推奨構成**
  - **クラウド × バッチ推論**
    - 夜間〜早朝に SageMaker Batch Transform や Processing Job で、全ユーザー分を一括スコアリング。  
    - 結果を DB に保存し、朝アプリを開いたときには即時に結果を表示。

- **理由**
  - 即時性より **スループットとコスト効率**が重要。
  - フリート全体での統計・分析も同時にできるので、サービス改善にも寄与。

- **ECU案**
  - 各車両がローカルに「今日のおすすめ」を計算することも理論的には可能だが、
    - 分析性・モデル更新・AB テスト
  - を考えるとクラウド側バッチが圧倒的に運用しやすいため、机上では優先度低の案と位置付けてよい。

---

### 3-2. 推奨充電タイミング前のリマインド推論

- **目的**
  - 「いつも 22:00 に自宅充電するユーザー」に対して、21:30 に
    - 「今日の推奨充電有無・推奨 SOC」
  - を通知する。

- **候補案**
  1. **朝バッチで計算済み → リマインドは通知だけ**
     - 朝のバッチ推論で「本日 22:00 充電予定＋今日の推奨値」を計算し、  
       21:30 にはその内容を push 通知するだけ。
  2. **リマインド直前にサーバレス推論**
     - EventBridge 等で 21:30 にジョブを起動し、そのタイミングで Serverless Endpoint or Lambda で最新状態を含めて推論。  

- **机上での結論**
  - 「直前に電気料金や天気など、追加情報を取り込みたいか」で選択が変わる。
  - 現時点（電力料金・外部要素をそこまで使わない前提）なら、**朝バッチ＋リマインド通知のみ**がシンプルで良さそう。
  - PoC 結果として「直前の情報を加味したい」という要件が出れば、「サーバレス推論追加」を第二ステップとして検討する方針でよい。

---

### 3-3. 充電前の突発リコメンド

- **目的**
  - 普段と違うタイミング・場所で充電しようとしたユーザーに対し、その場で推奨充電量・スキップ可否を返す。

- **トリガ例**
  - モバイルアプリの「今から充電、推奨量を教えて」ボタン押下。
  - 充電プラグ IN の検知。
  - 急速充電ステーションエリアへのジオフェンス侵入。

- **クラウド案：リアルタイム推論**
  - アプリ or 車載からクラウド API（SageMaker リアルタイム or Lambda）を呼び出し、1〜数秒で結果を返す。  

- **ECU案：リアルタイム推論**
  - 車両側で完結。
  - 通信圏外でも表示できるが、モデルの更新・高度な特徴量（外部情報）が使いにくい。

- **机上での整理**
  - 「どこで UX を中心に設計するか」で決まる。
    - アプリ中心 → クラウドリアルタイムが自然。
    - 車載ナビ中心 → ECUリアルタイムが自然。
  - 管理コストを考えると、**初期はクラウド側で統一し、ECU は将来の選択肢として保持**というステップ設計が現実的。

---

### 3-4. SOC が下限値を下回ったケース（SOC 10% 未満など）

- **目的**
  - 残量が危険域に入ったときに、「本当にいつもの充電ポイントまで到達できるか」を即座に評価して警告・提案したい。

- **検知 × 推論の分離**

  - **検知**：SOC が 10% を下回ったことを検知するのは ECU（BMS）で行うのが自然。
  - そこからの **推論の場所**は、設計方針によって分かれる。

- **パターン A：ECU 内で検知＆推論**
  - 完全オフラインでも安全機能を提供できる。
  - レイテンシ最小で、運転者への警告・ルート再計算などに向く。

- **パターン B：ECU で検知 → クラウドにリアルタイム API を投げる**
  - 「ECU で低下を検知し、そのイベントをクラウド API に投げてリアルタイム推論」も構成としては可能。
  - ただし、
    - 通信状況によっては応答が遅れる／返ってこない。
    - 安全に直結する判断をクラウド依存にするリスク。
  - があるため、**安全度の高い機能（到達不能リスク警告など）は、最終的には ECU 側で完結させる案が望ましい**と考えられる。  
    一方で、「そこまで緊急ではない補助的なアドバイス」であればクラウドリアルタイムも選択肢になる。

- **机上の結論**
  - このケースは、「機能の安全度クラス」が確定しないと最終判断ができない。
  - 方針としては：
    - 安全度 A（到達可能性に直接関わる） → **ECU推論を第1候補**。
    - 安全度 B（参考アドバイスレベル） → 「ECU検知＋クラウドリアルタイム」も検討対象に残す。

---

### 3-5. SOC が予測ラインより〇% 低下した場合の再推論

- **目的**
  - 事前に予測した SOC 軌跡から大きく外れた時に、計画を見直して再提案したい。

- **緊急度による整理**

1. **高緊急（このままだと到達不能リスクが高まりつつある）**
   - 検知・推論ともに ECU ストリーミングで行うのが筋。
   - 継続的に SOC と距離・ルートを評価し続ける構成。

2. **中〜低緊急（到達はできそうだが余裕が減ってきた）**
   - 一定間隔でクラウドにログを送信し、サーバレス推論で「最新の計画を更新」する構成もあり得る。
   - ここは「コールドスタートを UX 的に許容できるか」がサーバレス採用の鍵。  

---

## 4. 机上段階の対応方針（＝最終構成を決めるために何をするか）

ここは「最終構成そのもの」ではなく、**最終構成を決めるために必要な検討・比較項目**を定義する場所、と位置づける。

大きく以下の 4 ブロックに分けられる。

### 4-1. UX 観点で決めること

1. **ユースケースごとの UX 要件整理**
   - 朝定期リコメンド
   - 充電前突発リコメンド
   - リマインド
   - SOC 下限・予測逸脱時の警告
   など、それぞれについて：
   - どこでユーザーが結果を見るのか（アプリ／車載ナビ／メール）。
   - ユーザーがどれくらい待てるか（許容レイテンシ目標：例 0.1s / 1s / 5s）。
   - オフライン時の期待値（「通信がなくても最低限これだけは動いてほしい」）。

2. **オフライン要件の整理**
   - 停電・通信断時にも絶対に動かしたい機能（安全寄り）。
   - 通信があれば便利だが、なくても致命的ではない機能（快適性寄り）。

→ これにより、「UX 要件から見た ECU/クラウドの優先度」が決められる。

---

### 4-2. コスト・非機能要件（スケーラビリティ）で決めること

1. **クラウド案の概算コストモデル作成**
   - パターン例：
     - クラウド・バッチ＋クラウド・リアルタイム
     - クラウド・バッチ＋サーバレス
   - 前提として、
     - 1 ユーザーあたりの推論回数／日（朝定期 1 回＋突発 0.数回など）
     - ピーク時 QPS（例：夜間に集中する など）
   - を仮置きし、SageMaker リアルタイム／Serverless の料金モデルを使ってレンジ試算。  

2. **ECU 案の概算コストモデル作成**
   - ECU SoC・メモリ・フラッシュのグレードアップ分の BOM コスト増。
   - Edge Manager / Greengrass を使う場合のライセンス・運用コスト。  

3. **スケーラビリティ・運用負荷の評価**
   - クラウド案では、10 万ユーザー規模でのオートスケーリング・マルチ AZ・監視設計。
   - ECU 案では、10 万台への OTA 配信・バージョン管理・不具合時ロールバック手順。

→ コストと運用性の観点から、「クラウド案」「ECU案」「限定ハイブリッド案」の優劣を比較するのが対応方針になる（ML の予測精度とは独立）。

---

### 4-3. 技術的制約・実現可能性を確認すること

1. **ECU のベンチマーク**
   - 想定される ECU スペックに対して、ターゲットモデル（ONNX など）の推論時間・メモリ使用量を測定。
   - とくに SOC 下限・ストリーミング用途で必要な最大レイテンシと比較。

2. **ネットワークレイテンシ・可用性の測定**
   - 日本／北米／欧州の代表エリアで、
     - 車両 or モバイルから AWS リージョンまでの RTT 分布を測る（LTE/5G 前提）。
   - 「実際の分布」を見て、クラウドリアルタイムで UX 的に許容されるかを検証。

3. **データ量・帯域の評価**
   - 送信するテレマティクスの粒度（5 分単位かイベントのみか）によって、  
     帯域コストとバッチ/ストリーミング構成が変わる。

---

### 4-4. 比較・意思決定プロセスの定義

机上段階で明文化しておくと良さそうな「意思決定のステップ」は例えば次のような形。

1. **ユースケース × 緊急度 × UX 要件 マトリクスの確定**
2. **クラウド案・ECU案・限定ハイブリッド案の 3 パターン定義**
3. **各パターンについて、非機能（レイテンシ／可用性／運用性／コスト）のスコアリング**
4. **事業側と合意のうえ、「初期リリース構成」と「将来拡張の方向性」を決定**

ここまでが「机上段階の対応方針」として顧客に出せるメッセージになる。

---

## 5. 結論（現時点のまとめ）

- 推論場所（ECU vs クラウド）と推論手法（リアルタイム／バッチ／ストリーミング／サーバレス）について、  
  一般論＋EV 文脈での特徴・適用シーンを整理した。
- 今回のリコメンドユースケースに当てはめると：
  - 朝定期リコメンド → クラウド・バッチ推論が第 1 候補。
  - 充電前突発・リマインド → クラウド・リアルタイム or サーバレスが主。
  - SOC 下限・予測逸脱 → 検知は必ず ECU、推論は安全度に応じて ECU or クラウド。
- PoC フェーズでは、
  - **推論場所や手法そのものを決め切ること**よりも、
  - **UX と非機能要件（レイテンシ・コスト・運用）の観点から、最終構成を決めるために必要な情報と比較軸を定義すること**が重要。
- ML モデルの予測精度は、もちろん全体の価値を左右するものの、
  - 「クラウドに置くか ECU に置くか」
  - 「リアルタイムで呼ぶかバッチにするか」
  は基本的に **別次元の設計問題**であり、今回の整理は主に後者（推論アーキテクチャ）の話にフォーカスしている。

---

## 6. 未確定事項・今後の課題リスト（整理版）

1. ECU の実際のスペック（CPU/GPU/NPU、メモリ、ストレージ）と、それに対するモデルの推論ベンチマーク。
2. 日本・北米・欧州などでのモバイル→AWS リージョン間レイテンシ分布と、クラウドリアルタイム推論で許容できる UX の範囲。
3. 1 ユーザーあたりの想定推論回数／日・ピークパターンを仮置きしたうえでの、クラウド案の概算コストモデル。
4. ECU にモデルを載せる場合の BOM 増加・OTA 運用コストの概算。
5. 各ユースケースの緊急度ランク（安全度 A/B）と、それに応じた「ECU 必須かどうか」の整理。
6. 地域ごとのデータレジデンシ・プライバシ規制（GDPR 等）に基づく、クラウド側データ設計。
7. ONNX などのモデルフォーマット・量子化・Edge Manager/Neo 等を使うかどうかの技術選定。
8. クラウド案／ECU案／限定ハイブリッド案の 3 パターンについて、事業側を含めた比較評価プロセスの具体的な進め方。

---

## 7. 参考文献と参照内容

※「何がまとまっているページか」「本文のどの論点で参照したか」を簡潔に記載。

1. **Amazon SageMaker リアルタイム推論**  
   - URL: https://docs.aws.amazon.com/sagemaker/latest/dg/realtime-endpoints.html   
   - 内容: SageMaker のリアルタイムエンドポイントの概要。低レイテンシ・インタラクティブ用途向けで、常時起動 REST API として提供されることが説明されている。  
   - 使用箇所: 「クラウド × リアルタイム推論」の定義・用途、「推論手法」の整理。

2. **Amazon SageMaker Serverless Inference**  
   - URL: https://docs.aws.amazon.com/sagemaker/latest/dg/serverless-endpoints.html   
   - 内容: Serverless Inference の概要・料金モデル・コールドスタートの注意点。  
   - 使用箇所: 「サーバレス推論」の特徴（疎なトラフィック向け／コールドスタートあり）、「リマインド直前推論」などサーバレス候補案の説明。

3. **AWS Lambda Pricing & Cold Start 関連**  
   - URL: https://aws.amazon.com/lambda/pricing/   
   - 内容: Lambda の課金モデル（リクエスト数・実行時間・メモリ）、INIT フェーズ（コールドスタート）も課金対象であることなど。  
   - 使用箇所: サーバレス推論のコスト構造・コールドスタート説明。

4. **AWS IoT Greengrass – 機械学習推論**  
   - URL: https://docs.aws.amazon.com/greengrass/v2/developerguide/perform-machine-learning-inference.html   
   - 内容: Greengrass でクラウド学習モデルをエッジにデプロイし、ローカルデータで推論を行う方法。必要なストレージ・コンポーネント構成など。  
   - 使用箇所: ECU 側でのローカル推論の一般的なパターン、モデル配布・運用の難しさの背景説明。

5. **Edge Computing / Edge AI 総論（IoT 文脈）**  
   - URL: https://www.synaptics.com/company/blog/iot-edge-computing-ml   
   - 内容: エッジコンピューティングがクラウドだけの構成に比べて、レイテンシ・帯域・セキュリティの課題をどう補うか、IoT デバイス向けの設計指針。  
   - 使用箇所: 「ECU の特性（低レイテンシ・帯域節約・プライバシ）」の説明。

6. **Cloud vs Edge in IoT（ハイブリッドの整理）**  
   - URL: https://www.mdpi.com/2227-9709/11/4/71   
   - 内容: Edge はレイテンシ削減とプライバシに強く、クラウドはスケーラビリティと柔軟性に強いという比較。ハイブリッドアーキテクチャの有効性も論じている。  
   - 使用箇所: ECU vs クラウドの総論、および「限定的ハイブリッド案」をオプションとして扱う理由付け。

7. **McKinsey – Automotive Computing / Edge AI**  
   - URL: https://www.mckinsey.com/industries/semiconductors/our-insights/the-future-of-automotive-computing-cloud-and-edge   
   - 内容: 自動車コンピューティングにおけるクラウドとエッジの役割分担、ECU/SoC コスト増、5G・エッジ AI の潮流。  
   - 使用箇所: 「ECU 側のコスト増」「安全関連はエッジ側が重要になる」といった文脈。

8. **SageMaker Edge Manager + Greengrass 連携ブログ**  
   - URL: https://aws.amazon.com/blogs/machine-learning/build-machine-learning-at-the-edge-applications-using-amazon-sagemaker-edge-manager-and-aws-iot-greengrass-v2/   
   - 内容: モデルをクラウドで学習・最適化し、Greengrass 経由でエッジに配布・推論する一連のフロー。  
   - 使用箇所: ECU にモデルを載せるときの OTA／フリート運用のイメージと、その複雑さの背景。

9. **SageMaker Inference オプションの概要**  
   - URL: https://aws.amazon.com/sagemaker/ai/deploy/   
   - 内容: SageMaker のデプロイオプション（リアルタイム・バッチ・サーバレス・非同期）の整理。  
   - 使用箇所: 「推論手法」の体系的な整理（クラウド側オプションの定義）に利用。
