# SageMaker MLOps 概算コスト見積り（顧客報告用まとめ）
※本レポートは、(1)データ基盤、(2)CI/CDパイプラインを **コスト算出対象外** とし、以下に絞って整理する。  
対象：**(3)再学習トリガー / (4)再学習パイプライン / (5)モデル管理 / (6)推論**

---

## 0. 前提（与件・対象範囲）

### 0-1. 与件
- ユーザー数：**10万人**
- サービス利用地域：日本・北米・欧州  
  - コスト試算は **リージョン1か所固定**で実施（本番3リージョン展開は別途の増分として扱う）
- モデル構成：
  - **A：完全個人ごとに1モデル（10万モデル）**
  - **B：ユーザーグループごとにモデル（例：G=200モデル）**
  - **C：共通モデル（1モデル）**

### 0-2. コスト算出対象外（ユーザー要望）
- (1) データ基盤（S3/ETL/クエリ/監視ログ）
- (2) CI/CD（CodePipeline/CodeBuild/ECR等のビルド配布）

---

## 1. コスト支配要因の整理（結論）

### 1-1. 支配要因（最重要）
- **再学習（4）**は、原則「インスタンス時間課金」であり、  
  **モデル数 × 再学習頻度 × 1モデルあたり実行時間** に線形で効く。
- **A（10万モデル）**は「再学習ジョブ数」が支配的となり、  
  週次・日次にすると現実的な運用制約（同時実行枠、失敗率、オーケストレーション）が先にボトルネック化しやすい。
- **推論（6）**は「推論方式（serverless / real-time / batch）」と「SLO（遅延要求）」次第で支配項が変化する。  
  本件イベント頻度（後述）では、まず **Serverless または初乗車はBatch** が合理的。

---

## 2. (3) 再学習トリガー（スケジュール / ドリフト / モデル劣化）

### 2-1. 位置づけ
- EventBridge等による「トリガー発火」自体の課金は小さくなりやすい。
- 実コストは「トリガー後に起動される **Processing/Training** の計算コスト（= (4)）が支配」。

### 2-2. A/B/Cによる差
- **C**：トリガー回数が少なく、コスト影響は軽微
- **B**：グループ数に比例
- **A**：モデル数に比例（ただしトリガー費そのものより、後続ジョブが本質的課題）

---

## 3. (4) 再学習パイプライン（前処理→学習→評価→ゲート→デプロイ）

### 3-1. 課金の基本（重要）
- SageMaker Processing / Training / Batch Transform は基本的に **インスタンス × 実行時間**の従量課金。
- **並列数を上げても**、総実行時間（インスタンス時間の合計）が同等なら **総コストは大きく変わりにくい**。
  - 並列数は「完了までの壁時計時間」と「同時実行枠/ピーク負荷」に効く。

### 3-2. 標準ジョブ構成（CPU前提の推奨）
PoC〜初期商用のたたき台として、以下の「標準3段」を推奨：
- 前処理：Processing（`ml.m5.xlarge`〜`ml.m5.2xlarge`）
- 学習：Training（`ml.m5.xlarge`）
- 評価：Processing（`ml.m5.xlarge`〜`ml.m5.2xlarge`）
- ゲート：評価結果に基づき自動判定（合格なら自動デプロイ）

> 注：GPUが必要なモデル（深層学習等）の場合は別設計。

### 3-3. A/B/C別の「ジョブ数×並列数」設計指針

| モデル構成 | モデル数 | 再学習ジョブ数の特徴 | 推奨並列数K（同時実行） | コメント |
|---|---:|---|---:|---|
| C：共通 | 1 | 月次なら 1本（前処理+学習+評価） | 1 | 最も単純。まずCPU単一で成立。 |
| B：グループ | 例：200 | 月次なら 200本（グループ毎） | 10〜30 | 夜間で回すなど壁時計制約に合わせてKを調整。 |
| A：個人 | 100,000 | 月次でも10万本。運用制約が支配 | 非推奨（現実上破綻しやすい） | Aをやるなら “完全個人再学習”を避ける設計が必要。 |

### 3-4. A（完全個人モデル）を成立させるための現実的代替案
Aを要件として残す場合、以下いずれかへ寄せることを推奨：

- **A’：共通モデル + 個人補正（軽量パラメータ）**
  - 共通モデルはCと同等の再学習運用
  - 個人補正は小さな校正器/閾値/係数更新などに限定し、学習負荷を抑制

- **推論のみ個別（A推論）＋再学習はB/Cで運用**
  - 個別モデルは推論時にロードする方式（後述のMME等）
  - 再学習対象ユーザーを「データ十分な一部」に限定／イベント駆動へ変更

### 3-5. 「ECRやFeature Storeコストは気にしなくてよいか？」
- **ECR**：主にストレージ課金。通常は計算（Processing/Training）に比べて桁が小さくなりやすく、概算から外して差し支えないケースが多い。
- **Feature Store**：利用形態次第で無視できない場合がある（オンラインストア読み書き等）。  
  ただし「既存基盤で特徴量管理する」前提なら今回の算出対象外でよい。

---

## 4. (5) モデル管理コスト（成果物・メタデータ）

### 4-1. 自動デプロイ前提の整理
- 「評価ゲートを通過したら自動デプロイ」の設計により、定常的な人件費（オペレーション工数）は抑制可能。
- ただしAWS課金としては、以下が残る：
  - 成果物の保管（S3等）
  - （採用するなら）モデルモニタリング/評価ジョブの計算コスト（Processingジョブとして発生）

### 4-2. A/B/C別の特徴
| モデル構成 | モデル管理（保管）費の傾向 | 運用の難しさ（定性的） |
|---|---|---|
| C | 小 | 低 |
| B | 中（モデル数に比例） | 中（グループ追加/統廃合など） |
| A | 大（モデル数に比例） | 高（整合性、ロールバック、配布/参照の複雑性） |

---

## 5. (6) 推論コスト設計（イベント別：方式選定・同時並列の考え方）

### 5-1. 想定推論イベント（与件）
- **その日の初乗車イベント**：1日1回/ユーザー  
  - 10万人 → **10万回/日**
- **充電前タイミング**：3日に1回/ユーザー  
  - 10万人 → **約3.3万回/日**
- 合計：**約13.3万回/日**（≒約400万回/月）

### 5-2. 方式別の適用性（推奨）

| 推論方式 | 適用性 | 長所 | 注意点 |
|---|---|---|---|
| Serverless Inference | 初乗車/充電前とも有力 | 常時課金なし。スパイクに強い。運用単純。 | コールドスタート/同時実行制限がSLOに影響する場合あり（対策：Provisioned Concurrency）。 |
| Real-time Endpoint（常時起動） | 条件次第 | 低遅延・安定SLO。高スループット向き。 | トラフィックが薄いと割高（アイドルでも時間課金）。 |
| Batch Transform | 初乗車向け（条件付き） | 朝までに準備できれば最も安定/低運用。 | 充電直前など“オンデマンド”には不向き。 |

### 5-3. イベント別の推奨構成
- **初乗車（1日1回）**
  - 予測を“当日朝までに用意できればOK”なら：**Batch Transform 推奨**
    - 前日深夜〜早朝に全ユーザー分を一括作成し、アプリ/サーバで参照
  - “初乗車時に必ず最新推論が必要”なら：**Serverless 推奨**
- **充電前（3日に1回）**
  - ユーザーの充電タイミングはオンデマンド性が高いため：**Serverless 推奨**
  - SLOが厳しく、常時一定トラフィックがあるなら：Real-timeも検討余地

### 5-4. 同時並列（Concurrency）設計の考え方
- **Serverless**：同時実行数をパラメータとして制御可能。必要なら **Provisioned Concurrency**でコールドスタートを抑制。
- **Real-time**：インスタンス台数/サイズでスループットを確保。信頼性要件がある場合、複数台（Multi-AZ相当）を前提にする。
- **Batch**：インスタンス数（並列）×実行時間で壁時計時間を調整。

---

## 6. A/B/Cと推論（エンドポイント数/運用）の現実解

| モデル構成 | 推奨デプロイ形態 | コメント |
|---|---|---|
| C：共通（1モデル） | Serverless 1つ or Real-time 1系統 | 最も単純。イベント別にBatch併用もしやすい。 |
| B：グループ（Gモデル） | 可能なら「入力にグループ特徴を持たせて1モデル化」→Cに寄せる | エンドポイントをG個に増やすのは運用が重い。 |
| A：個人（10万モデル） | **10万エンドポイントは不可**。実施するなら **MME等で集約** | 個別モデルのロード/キャッシュ効率が性能・コストを左右。完全個人再学習は要再設計。 |

---

## 7. 顧客向け要点まとめ（意思決定ポイント）

### 7-1. コスト面の要点
- (4)再学習は **モデル数 × 頻度** が支配。  
  **A（10万モデル）を“定期再学習”で回す設計は極めて重い**。
- 推論はイベント頻度から、まず **Serverless中心**が合理的。  
  初乗車は「朝までに準備できる」なら **Batch化**でさらに運用安定。

### 7-2. 推奨する初期方針（PoC→初期商用）
- 再学習：**CまたはB**を基本線（Aは代替案A’を推奨）
- 推論：
  - 初乗車：**Batch（可能なら） or Serverless**
  - 充電前：**Serverless**
- Aを要件として残す場合：  
  **共通モデル+個人補正（A’）**、または **推論のみ個別（MME前提）**へ寄せて成立性を確保

---

## 8. 次ステップ（概算費用へ落とすための最小パラメータ）
本整理を「概算費用（レンジ）」へ落とすには、以下2点の実測/仮置きが最重要：
1) 推論1回あたり平均実行時間（ms）  
2) 再学習頻度（週次/月次/イベント駆動）と Bのグループ数G（例：50/200/1000の感度）

（これらを置くことで、(4)と(6)の金額レンジを表形式で算出可能）
